{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "66fef5bb",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "For development testing, you can setup a local Postgres Vector container like this:\n",
    "```bash\n",
    "# Pull a postgres image with pgvector installed\n",
    "podman pull pgvector/pgvector:pg17\n",
    "\n",
    "# Start the postgres container\n",
    "podman run --name postgres -it --rm -e POSTGRES_USER=postgres -e POSTGRES_HOST_AUTH_METHOD=trust -p 5432:5432 pgvector/pgvector:pg17\n",
    "\n",
    "# In a new terminal tab, create the necessary databases\n",
    "createdb -h localhost -p 5432 -U postgres store\n",
    "createdb -h localhost -p 5432 -U postgres checkpoint\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bc3ce9da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "import itertools\n",
    "\n",
    "import psycopg\n",
    "import psycopg_pool\n",
    "from psycopg import rows\n",
    "\n",
    "from google import genai\n",
    "from google.genai import types\n",
    "\n",
    "# from langgraph.store.memory import InMemoryStore\n",
    "from langgraph.store.postgres import AsyncPostgresStore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "66bb7915",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT_ID = \"genai-experience-concierge\"\n",
    "LOCATION = \"us-central1\"\n",
    "EMBEDDING_MODEL_NAME = \"text-embedding-005\"\n",
    "\n",
    "PG_CONNECTION_URL = \"postgresql://postgres@localhost:5432/store\"\n",
    "\n",
    "genai_client = genai.Client(\n",
    "    vertexai=True,\n",
    "    project=PROJECT_ID,\n",
    "    location=LOCATION,\n",
    ")\n",
    "\n",
    "store_pool = psycopg_pool.AsyncConnectionPool(\n",
    "    conninfo=PG_CONNECTION_URL,\n",
    "    connection_class=psycopg.AsyncConnection[rows.DictRow],\n",
    "    kwargs={\"autocommit\": True, \"row_factory\": rows.dict_row},\n",
    "    open=False,\n",
    ")\n",
    "await store_pool.open()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1f8039c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VertexAIEmbeddings:\n",
    "    def __init__(\n",
    "        self,\n",
    "        model_name: str,\n",
    "        client: genai.Client,\n",
    "        batch_size: int = 250,\n",
    "        title: str | None = None,\n",
    "        auto_truncate: bool = False,\n",
    "        task_type: str | None = None,\n",
    "        mime_type: str | None = None,\n",
    "        output_dimensionality: int = 768,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.client = client\n",
    "        self.output_dimensionality = output_dimensionality\n",
    "        self.batch_size = min(batch_size, 250)\n",
    "        self.title = title\n",
    "        self.auto_truncate = auto_truncate\n",
    "        self.task_type = task_type\n",
    "        self.model_name = model_name\n",
    "        self.mime_type = mime_type\n",
    "\n",
    "    async def embed(self, documents: list[str]) -> list[list[float]]:\n",
    "        batch_embedding_futures = [\n",
    "            self.client.aio.models.embed_content(\n",
    "                model=self.model_name,\n",
    "                contents=query_batch,\n",
    "                config=types.EmbedContentConfig(\n",
    "                    task_type=self.task_type,\n",
    "                    title=self.title,\n",
    "                    output_dimensionality=self.output_dimensionality,\n",
    "                    mime_type=self.mime_type,\n",
    "                    auto_truncate=self.auto_truncate,\n",
    "                ),\n",
    "            )\n",
    "            for query_batch in itertools.batched(documents, n=self.batch_size)\n",
    "        ]\n",
    "\n",
    "        embedding_batches = await asyncio.gather(*batch_embedding_futures)\n",
    "\n",
    "        embeddings = [\n",
    "            embedding.values\n",
    "            for batch in embedding_batches\n",
    "            for embedding in batch.embeddings or []\n",
    "            if embedding.values is not None\n",
    "        ]\n",
    "\n",
    "        if len(embeddings) != len(documents):\n",
    "            raise ValueError(\n",
    "                \"Count of valid embeddings doesn't match the number of input documents.\"\n",
    "                f\"Expected: {len(documents)}. Received: {len(embeddings)}\"\n",
    "            )\n",
    "\n",
    "        return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fb745f5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'v': 3}\n",
      "{'v': 2}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Task pending name='ttl_sweeper' coro=<AsyncPostgresStore.start_ttl_sweeper.<locals>._sweep_loop() running at /Users/pablogaeta/work/generative-ai/gemini/agents/genai-experience-concierge/langgraph-demo/backend/.venv/lib/python3.12/site-packages/langgraph/store/postgres/aio.py:313>>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_model = VertexAIEmbeddings(\n",
    "    model_name=EMBEDDING_MODEL_NAME,\n",
    "    client=genai_client,\n",
    "    task_type=\"RETRIEVAL_QUERY\",\n",
    ")\n",
    "\n",
    "pg_store = AsyncPostgresStore(\n",
    "    conn=store_pool,\n",
    "    index={\n",
    "        \"embed\": embedding_model.embed,\n",
    "        \"dims\": embedding_model.output_dimensionality,\n",
    "        \"fields\": [\"text\"],\n",
    "    },\n",
    "    ttl={\n",
    "        \"default_ttl\": 60,\n",
    "        \"refresh_on_read\": False,\n",
    "        \"sweep_interval_minutes\": 1,\n",
    "    },\n",
    ")\n",
    "\n",
    "await pg_store.setup()\n",
    "await pg_store.start_ttl_sweeper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c2dcc667",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Item(namespace=['docs'], key='doc1', value={'text': 'Python tutorial'}, created_at='2025-04-12T00:06:32.607700+00:00', updated_at='2025-04-12T00:06:32.607700+00:00', score=0.657091599606646),\n",
       " Item(namespace=['docs'], key='doc2', value={'text': 'TypeScript guide'}, created_at='2025-04-12T00:06:32.837157+00:00', updated_at='2025-04-12T00:06:32.837157+00:00', score=0.424146806489476)]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "await pg_store.aput((\"docs\",), \"doc1\", {\"text\": \"Python tutorial\"}, ttl=1)\n",
    "await pg_store.aput((\"docs\",), \"doc2\", {\"text\": \"TypeScript guide\"}, ttl=1)\n",
    "\n",
    "# Search by similarity\n",
    "await pg_store.asearch((\"docs\",), query=\"python programming\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "955f4d8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "await pg_store.asearch((\"docs\",), query=\"python programming\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ce28cf28",
   "metadata": {},
   "outputs": [],
   "source": [
    "await store_pool.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
